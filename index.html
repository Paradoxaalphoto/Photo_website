<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>YorN — Alpha (Preprocess + Retry)</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.1/dist/chart.umd.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.21.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <style>.mono{font-family:ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace}</style>
</head>
<body class="bg-gray-50 text-gray-900">
  <div class="max-w-4xl mx-auto p-4 space-y-4">
    <header>
      <h1 class="text-2xl font-bold">YorN — Alpha</h1>
      <p class="text-sm text-gray-600">Select photo → Preview → <b>Analyze</b>. Added preprocessing to improve detection.</p>
    </header>

    <section class="grid md:grid-cols-[1fr_auto] gap-3 items-end bg-white p-4 rounded-xl shadow">
      <input id="fileInput" type="file" accept="image/*" class="border p-2 rounded w-full" />
      <div class="flex gap-2">
        <button id="analyzeBtn" class="px-4 py-2 bg-blue-600 text-white rounded disabled:opacity-50" disabled>Analyze</button>
      </div>
      <div class="col-span-full w-full bg-gray-200 h-2 rounded overflow-hidden">
        <div id="progressBar" class="bg-blue-600 h-2 w-0"></div>
      </div>
      <div id="progressText" class="col-span-full text-xs text-gray-600"></div>
    </section>

    <section class="grid md:grid-cols-2 gap-4">
      <div class="bg-white p-4 rounded-xl shadow">
        <h2 class="text-sm font-semibold mb-2">Preview</h2>
        <img id="thumb" class="hidden w-full max-h-96 object-contain rounded border bg-white" alt="Selected preview" />
        <canvas id="overlay" class="hidden border rounded bg-white mt-3"></canvas>
      </div>
      <div class="bg-white p-4 rounded-xl shadow">
        <h2 class="text-sm font-semibold mb-2">Diagnostics</h2>
        <div id="diag" class="text-xs mono whitespace-pre-wrap bg-gray-50 border rounded p-2 max-h-80 overflow-auto">No diagnostics yet.</div>
        <div id="errorBox" class="text-sm text-red-700 bg-red-50 border border-red-200 rounded p-2 mt-2 hidden"></div>
      </div>
    </section>

    <section class="bg-white p-4 rounded-xl shadow">
      <h2 class="text-sm font-semibold mb-2">Chart</h2>
      <canvas id="scoreChart" class="hidden"></canvas>
    </section>
  </div>

<script>
const CDNS = [
  "https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights",
  "https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights"
];
let WEIGHTS=null, modelsLoaded=false, imageBlobUrl=null;

const $ = id=>document.getElementById(id);
const fileInput=$("fileInput"), analyzeBtn=$("analyzeBtn"), thumb=$("thumb"), overlay=$("overlay");
const progressBar=$("progressBar"), progressText=$("progressText"), diag=$("diag"), errorBox=$("errorBox"), chart=$("scoreChart");

function setProgress(p,t){ progressBar.style.width=(p||0)+'%'; progressText.textContent=t||''; }
function logDiag(obj){ const now=new Date().toISOString(); const txt=typeof obj==='string'?obj:JSON.stringify(obj,null,2); diag.textContent=`[${now}]\n${txt}\n\n`+diag.textContent; }
function setError(msg){ errorBox.textContent=msg; errorBox.classList.remove("hidden"); logDiag({error:msg}); }
function clearError(){ errorBox.textContent=""; errorBox.classList.add("hidden"); }

fileInput.addEventListener("change", ()=>{
  if(!fileInput.files.length){ analyzeBtn.disabled=true; return; }
  const f=fileInput.files[0];
  imageBlobUrl=URL.createObjectURL(f);
  thumb.src=imageBlobUrl; thumb.classList.remove("hidden");
  analyzeBtn.disabled=false; overlay.classList.add("hidden"); chart.classList.add("hidden");
  clearError(); setProgress(0,""); logDiag({fileName:f.name, type:f.type, size_bytes:f.size});
});

async function pickWeightsCdn(){
  for(const b of CDNS){
    try{ const res=await fetch(b+"/face_landmark_68_model-weights_manifest.json",{method:"HEAD"});
      if(res.ok){ WEIGHTS=b; logDiag({usingWeightsFrom:b}); return; }
      logDiag({cdnAttempt:b, status:res.status});
    }catch(e){ logDiag({cdnAttempt:b, error:e&&e.message}); }
  }
  throw new Error("No working CDN for weights");
}

async function ensureModels(){
  if(modelsLoaded) return;
  setProgress(6,"Selecting CDN…"); if(!WEIGHTS) await pickWeightsCdn();
  setProgress(12,"Loading TFJS…"); await tf.ready();
  setProgress(22,"Loading TinyFaceDetector…"); await faceapi.nets.tinyFaceDetector.loadFromUri(WEIGHTS);
  setProgress(40,"Loading Landmarks…"); await faceapi.nets.faceLandmark68Net.loadFromUri(WEIGHTS);
  modelsLoaded=true; setProgress(50,"Models ready."); logDiag({detector:"TinyFaceDetector", modelsLoaded});
}

function downscaleAndAdjust(img, maxDim=1024, rotate=0, bright=1.0, contrast=1.0){
  const maxSide = Math.max(img.width, img.height);
  const scale = Math.min(1, maxDim / maxSide);
  const w = Math.round((rotate%180===0? img.width: img.height) * scale);
  const h = Math.round((rotate%180===0? img.height: img.width) * scale);
  const canvas = document.createElement('canvas');
  canvas.width = w; canvas.height = h;
  const ctx = canvas.getContext('2d');
  ctx.translate(w/2, h/2);
  ctx.rotate(rotate*Math.PI/180);
  ctx.filter = `brightness(${bright}) contrast(${contrast})`;
  ctx.drawImage(img, -img.width*scale/2, -img.height*scale/2, img.width*scale, img.height*scale);
  const out = new Image();
  out.src = canvas.toDataURL('image/jpeg', 0.92);
  out.width = w; out.height = h;
  return new Promise(res=> out.onload=()=> res(out));
}

function detectWithTimeout(img, opts, ms=3500){
  return Promise.race([
    faceapi.detectSingleFace(img, opts).withFaceLandmarks(true),
    new Promise((_,rej)=> setTimeout(()=> rej(new Error("Detection timeout")), ms))
  ]);
}

async function analyze(){
  try{
    clearError(); setProgress(5,"Starting…"); await ensureModels();
    if(!imageBlobUrl){ setProgress(0,"Choose a photo first."); return; }
    setProgress(58,"Loading image…");
    const raw = new Image();
    raw.onload = async ()=>{
      overlay.classList.add("hidden");
      const variants = [
        { rotate:0, bright:1.0, contrast:1.0 },
        { rotate:90, bright:1.0, contrast:1.0 },
        { rotate:270, bright:1.0, contrast:1.0 },
        { rotate:0, bright:1.15, contrast:1.0 },
        { rotate:0, bright:1.0, contrast:1.2 },
      ];
      const sizes = [480, 416, 320, 256];
      let det=null, used={};
      for(const v of variants){
        const pre = await downscaleAndAdjust(raw, 1024, v.rotate, v.bright, v.contrast);
        overlay.width = pre.width; overlay.height = pre.height;
        const displaySize = { width: pre.width, height: pre.height };
        for(const s of sizes){
          try{
            setProgress(70, `Detecting (rot ${v.rotate}°, input ${s})…`);
            const opts = new faceapi.TinyFaceDetectorOptions({ inputSize: s, scoreThreshold: 0.3 });
            det = await detectWithTimeout(pre, opts, 4000);
            used = { rotate: v.rotate, inputSize: s, bright: v.bright, contrast: v.contrast };
            if(det) break;
          }catch(e){
            logDiag({ attempt:{rotate:v.rotate, inputSize:s, bright:v.bright, contrast:v.contrast}, error:e&&e.message });
            await tf.nextFrame();
          }
        }
        if(det) { 
          // Basic min-size guard: require face box to be at least 10% of min dimension
          const box = det.detection.box; 
          const minDim = Math.min(pre.width, pre.height);
          if (Math.max(box.width, box.height) < 0.1 * minDim) {
            logDiag({ warning: "Face too small after scaling", box });
          } else {
            break;
          }
        }
      }
      if(!det){ setProgress(0,""); setError("Still couldn’t detect a face. Try a front-facing photo with your face larger in frame."); return; }

      setProgress(86,"Drawing landmarks…");
      const ctx = overlay.getContext('2d');
      ctx.clearRect(0,0,overlay.width,overlay.height);
      ctx.drawImage(raw, 0,0, overlay.width, overlay.height);
      const resized = faceapi.resizeResults(det, { width: overlay.width, height: overlay.height });
      faceapi.draw.drawFaceLandmarks(overlay, resized);
      overlay.classList.remove("hidden");
      logDiag({ success:true, used });

      setProgress(100,"Done.");
      setTimeout(()=> setProgress(0,""), 1500);
    };
    raw.src = imageBlobUrl;
  }catch(e){
    setError("Error during analysis: " + (e && e.message));
    setProgress(0,"");
  }
}

document.getElementById("analyzeBtn").addEventListener("click", analyze);
</script>
</body>
</html>
